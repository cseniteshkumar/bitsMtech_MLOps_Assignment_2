{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b6497f2",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db2f1f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices found: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU(s) available: 1\n",
      "GPU names: ['/physical_device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enable CUDA GPU usage\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Configure TensorFlow to use GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Physical devices found:\", physical_devices)\n",
    "if physical_devices:\n",
    "    try:\n",
    "        # Enable memory growth to avoid allocating all GPU memory at once\n",
    "        for device in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(device, True)\n",
    "        print(f\"GPU(s) available: {len(physical_devices)}\")\n",
    "        print(f\"GPU names: {[device.name for device in physical_devices]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error configuring GPU:\")\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")\n",
    "\n",
    "\n",
    "# Set mixed precision for better performance (optional)\n",
    "# from tensorflow.keras import mixed_precision\n",
    "# mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742e51f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For reproducibility\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a9089f",
   "metadata": {},
   "source": [
    "Define image properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c72db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Width=128\n",
    "Image_Height=128\n",
    "Image_Size=(Image_Width,Image_Height)\n",
    "Image_Channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d9dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFilesPath = './DataFiles/train/'\n",
    "testFilesPath = './DataFiles/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d44b3",
   "metadata": {},
   "source": [
    "Prepare dataset for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1df0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=os.listdir(trainFilesPath)\n",
    "categories=[]\n",
    "for f_name in filenames:\n",
    "    category=f_name.split('.')[0]\n",
    "    if category=='dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "df=pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69e414f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='category'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(df.shape)\n",
    "# print(df.head())\n",
    "\n",
    "## select 100 rows from the dataframe \n",
    "df = df.sample(100)\n",
    "print(df.shape)\n",
    "\n",
    "## print the description of the dataframe by considering only the category column as categorical data\n",
    "# print(df['category'].astype('category').describe())\n",
    "\n",
    "### visualize the distribution of the categories in the dataframe by using a bar plot\n",
    "df['category'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac18d28",
   "metadata": {},
   "source": [
    "Create the neural net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a40586e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1771676990.111259   92975 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9452 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,\\\n",
    "     Dropout,Flatten,Dense,Activation,\\\n",
    "     BatchNormalization\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(Image_Width,Image_Height,Image_Channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "  optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d158bf",
   "metadata": {},
   "source": [
    "Analyzing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcdcfd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m12,845,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m1,026\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,942,786</span> (49.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,942,786\u001b[0m (49.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,941,314</span> (49.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,941,314\u001b[0m (49.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,472</span> (5.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,472\u001b[0m (5.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e76a403",
   "metadata": {},
   "source": [
    "Define callbacks and learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50099d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience = 10)\n",
    "\n",
    "\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',patience = 2,verbose = 1,factor = 0.5,min_lr = 0.00001)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy', \n",
    "    patience=2, \n",
    "    verbose=1, \n",
    "    factor=0.5, \n",
    "    min_lr=0.00001)\n",
    "\n",
    "callbacks = [earlystop,learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584435db",
   "metadata": {},
   "source": [
    "Manage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0:'cat',1:'dog'})\n",
    "train_df,validate_df = train_test_split(df,test_size=0.20,\n",
    "  random_state=42)\n",
    "#### test DF\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "total_train=train_df.shape[0]\n",
    "total_validate=validate_df.shape[0]\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1efb81a",
   "metadata": {},
   "source": [
    "Test data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c920bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test DF\n",
    "test_filenames = os.listdir(testFilesPath)\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c869662",
   "metadata": {},
   "source": [
    "Training and validation data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73d3b418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 validated image filenames belonging to 2 classes.\n",
      "Found 20 validated image filenames belonging to 2 classes.\n",
      "Found 12500 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1\n",
    "                                )\n",
    "\n",
    "# train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "#                                                  \"./dogs-vs-cats/train/\",\n",
    "#                                                  x_col='filename',\n",
    "#                                                  y_col='category',\n",
    "#                                                  target_size=Image_Size,\n",
    "#                                                  class_mode='categorical',\n",
    "#                                                  batch_size=batch_size)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 trainFilesPath,  # Use defined variable\n",
    "                                                 x_col='filename',\n",
    "                                                 y_col='category',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=batch_size)\n",
    "\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# validation_generator = validation_datagen.flow_from_dataframe(\n",
    "#     validate_df, \n",
    "#     \"./dogs-vs-cats/train/\", \n",
    "#     x_col='filename',\n",
    "#     y_col='category',\n",
    "#     target_size=Image_Size,\n",
    "#     class_mode='categorical',\n",
    "#     batch_size=batch_size\n",
    "# )\n",
    "\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    trainFilesPath,  # Use defined variable\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=Image_Size,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1)\n",
    "\n",
    "# test_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "#                                                  \"./dogs-vs-cats/test/\",x_col='filename',y_col='category',\n",
    "#                                                  target_size=Image_Size,\n",
    "#                                                  class_mode='categorical',\n",
    "#                                                  batch_size=batch_size)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(test_df,  # Use test_df\n",
    "                                                 testFilesPath,  # Use defined variable\n",
    "                                                 x_col='filename',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode=None,  # No labels for test\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa467f8",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c9f8bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "epochs=10\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e5c366",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc74d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"model1_catsVSdogs_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b5204f",
   "metadata": {},
   "source": [
    "Make categorical prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8680c59",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m predict = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_generator\u001b[49m(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
      "\u001b[31mAttributeError\u001b[39m: 'Sequential' object has no attribute 'predict_generator'"
     ]
    }
   ],
   "source": [
    "predict = model.predict(test_generator, steps=np.ceil(nb_samples/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d72fa",
   "metadata": {},
   "source": [
    "Convert labels to categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38571ca8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_df[\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m] = np.argmax(\u001b[43mpredict\u001b[49m, axis=-\u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m label_map = \u001b[38;5;28mdict\u001b[39m((v,k) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m train_generator.class_indices.items())\n\u001b[32m      4\u001b[39m test_df[\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m] = test_df[\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m].replace(label_map)\n",
      "\u001b[31mNameError\u001b[39m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "test_df['category'] = np.argmax(predict, axis=-1)\n",
    "\n",
    "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "test_df['category'] = test_df['category'].replace(label_map)\n",
    "\n",
    "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a8d05",
   "metadata": {},
   "source": [
    "Visualize the prediction results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6eb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = test_df.head(18)\n",
    "sample_test.head()\n",
    "plt.figure(figsize=(12, 24))\n",
    "for index, row in sample_test.iterrows():\n",
    "    filename = row['filename']\n",
    "    category = row['category']\n",
    "    img = load_img(testFilesPath + filename, target_size=Image_Size)  # Fixed path\n",
    "    plt.subplot(6, 3, index+1)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de67db3",
   "metadata": {},
   "source": [
    "Test your model performance on custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results={\n",
    "#     0:'cat',\n",
    "#     1:'dog'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a1f63",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '__image_path_TO_custom_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m im=\u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m__image_path_TO_custom_image\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m im=im.resize(Image_Size)\n\u001b[32m     17\u001b[39m im=np.expand_dims(im,axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/niteshkumar/SSD_Store_0_nvme/allPythoncodesWithPipEnv/BitsLearning/MLOps_Assignment/Assignment_2/bitsMtech_MLOps_Assignment_2/.mlopsAssignment2Env/lib/python3.12/site-packages/PIL/Image.py:3512\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[32m   3511\u001b[39m     filename = os.fspath(fp)\n\u001b[32m-> \u001b[39m\u001b[32m3512\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3513\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3514\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '__image_path_TO_custom_image'"
     ]
    }
   ],
   "source": [
    "# # im=Image.open(\"__image_path_TO_custom_image\")\n",
    "# # im=im.resize(Image_Size)\n",
    "# # im=np.expand_dims(im,axis=0)\n",
    "# # im=np.array(im)\n",
    "# # im=im/255\n",
    "# # pred_probs = model.predict(im)\n",
    "# # pred = np.argmax(pred_probs, axis=-1)[0]\n",
    "# # print(pred, results[pred])\n",
    "\n",
    "\n",
    "# # Replace with actual image path\n",
    "# image_path = \"__image_path_TO_custom_image\"  # Define your actual path here\n",
    "# im = Image.open(image_path)\n",
    "# im = im.resize(Image_Size)\n",
    "# im = np.expand_dims(im, axis=0)\n",
    "# im = np.array(im)\n",
    "# im = im / 255\n",
    "# pred_probs = model.predict(im)\n",
    "# pred = np.argmax(pred_probs, axis=-1)[0]\n",
    "# print(f\"Prediction: {pred}, Class: {results[pred]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9820f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd987c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed7943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlopsAssignment2Env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
