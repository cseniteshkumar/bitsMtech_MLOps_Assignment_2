{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b6497f2",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db2f1f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices found: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU(s) available: 1\n",
      "GPU names: ['/physical_device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enable CUDA GPU usage\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Configure TensorFlow to use GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Physical devices found:\", physical_devices)\n",
    "if physical_devices:\n",
    "    try:\n",
    "        # Enable memory growth to avoid allocating all GPU memory at once\n",
    "        for device in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(device, True)\n",
    "        print(f\"GPU(s) available: {len(physical_devices)}\")\n",
    "        print(f\"GPU names: {[device.name for device in physical_devices]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error configuring GPU:\")\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")\n",
    "\n",
    "\n",
    "# Set mixed precision for better performance (optional)\n",
    "# from tensorflow.keras import mixed_precision\n",
    "# mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a9089f",
   "metadata": {},
   "source": [
    "Define image properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c72db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Width=128\n",
    "Image_Height=128\n",
    "Image_Size=(Image_Width,Image_Height)\n",
    "Image_Channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d9dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFilesPath = './DataFiles/train/'\n",
    "testFilesPath = './DataFiles/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d44b3",
   "metadata": {},
   "source": [
    "Prepare dataset for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1df0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=os.listdir(trainFilesPath)\n",
    "categories=[]\n",
    "for f_name in filenames:\n",
    "    category=f_name.split('.')[0]\n",
    "    if category=='dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "df=pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69e414f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='category'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(df.shape)\n",
    "# print(df.head())\n",
    "\n",
    "## select 100 rows from the dataframe \n",
    "df = df.sample(100)\n",
    "print(df.shape)\n",
    "\n",
    "## print the description of the dataframe by considering only the category column as categorical data\n",
    "# print(df['category'].astype('category').describe())\n",
    "\n",
    "### visualize the distribution of the categories in the dataframe by using a bar plot\n",
    "df['category'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac18d28",
   "metadata": {},
   "source": [
    "Create the neural net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a40586e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1771676353.325434   87809 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9426 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,\\\n",
    "     Dropout,Flatten,Dense,Activation,\\\n",
    "     BatchNormalization\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(Image_Width,Image_Height,Image_Channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "  optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d158bf",
   "metadata": {},
   "source": [
    "Analyzing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcdcfd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m12,845,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m1,026\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,942,786</span> (49.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,942,786\u001b[0m (49.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,941,314</span> (49.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,941,314\u001b[0m (49.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,472</span> (5.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,472\u001b[0m (5.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e76a403",
   "metadata": {},
   "source": [
    "Define callbacks and learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50099d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience = 10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',patience = 2,verbose = 1,factor = 0.5,min_lr = 0.00001)\n",
    "callbacks = [earlystop,learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584435db",
   "metadata": {},
   "source": [
    "Manage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9260336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0:'cat',1:'dog'})\n",
    "train_df,validate_df = train_test_split(df,test_size=0.20,\n",
    "  random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "total_train=train_df.shape[0]\n",
    "total_validate=validate_df.shape[0]\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c869662",
   "metadata": {},
   "source": [
    "Training and validation data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73d3b418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1\n",
    "                                )\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"./dogs-vs-cats/train/\",x_col='filename',y_col='category',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=batch_size)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    \"./dogs-vs-cats/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=Image_Size,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1)\n",
    "\n",
    "test_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"./dogs-vs-cats/test/\",x_col='filename',y_col='category',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa467f8",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c9f8bbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The PyDataset has length 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# epochs=10\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# history = model.fit_generator(\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#     train_generator, \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#     callbacks=callbacks\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     12\u001b[39m epochs=\u001b[32m10\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_validate\u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_train\u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/niteshkumar/SSD_Store_0_nvme/allPythoncodesWithPipEnv/BitsLearning/MLOps_Assignment/Assignment_2/bitsMtech_MLOps_Assignment_2/.mlopsAssignment2Env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/niteshkumar/SSD_Store_0_nvme/allPythoncodesWithPipEnv/BitsLearning/MLOps_Assignment/Assignment_2/bitsMtech_MLOps_Assignment_2/.mlopsAssignment2Env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:311\u001b[39m, in \u001b[36mPyDatasetAdapter.get_tf_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    306\u001b[39m     batches = [\n\u001b[32m    307\u001b[39m         \u001b[38;5;28mself\u001b[39m._standardize_batch(\u001b[38;5;28mself\u001b[39m.py_dataset[i])\n\u001b[32m    308\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples)\n\u001b[32m    309\u001b[39m     ]\n\u001b[32m    310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batches) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe PyDataset has length 0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    312\u001b[39m     \u001b[38;5;28mself\u001b[39m._output_signature = data_adapter_utils.get_tensor_spec(batches)\n\u001b[32m    314\u001b[39m ds = tf.data.Dataset.from_generator(\n\u001b[32m    315\u001b[39m     \u001b[38;5;28mself\u001b[39m._get_iterator,\n\u001b[32m    316\u001b[39m     output_signature=\u001b[38;5;28mself\u001b[39m._output_signature,\n\u001b[32m    317\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: The PyDataset has length 0"
     ]
    }
   ],
   "source": [
    "# epochs=10\n",
    "# history = model.fit_generator(\n",
    "#     train_generator, \n",
    "#     epochs=epochs,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=total_validate//batch_size,\n",
    "#     steps_per_epoch=total_train//batch_size,\n",
    "#     callbacks=callbacks\n",
    "# )\n",
    "\n",
    "\n",
    "epochs=10\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e5c366",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffcc74d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"model1_catsVSdogs_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9681f244",
   "metadata": {},
   "source": [
    "Test data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b67c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(testFilesPath)\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b5204f",
   "metadata": {},
   "source": [
    "Make categorical prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8680c59",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m predict = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_generator\u001b[49m(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
      "\u001b[31mAttributeError\u001b[39m: 'Sequential' object has no attribute 'predict_generator'"
     ]
    }
   ],
   "source": [
    "# predict = mode.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
    "\n",
    "\n",
    "predict = model.predict(test_generator, steps=np.ceil(nb_samples/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d72fa",
   "metadata": {},
   "source": [
    "Convert labels to categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38571ca8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_df[\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m] = np.argmax(\u001b[43mpredict\u001b[49m, axis=-\u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m label_map = \u001b[38;5;28mdict\u001b[39m((v,k) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m train_generator.class_indices.items())\n\u001b[32m      4\u001b[39m test_df[\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m] = test_df[\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m].replace(label_map)\n",
      "\u001b[31mNameError\u001b[39m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "test_df['category'] = np.argmax(predict, axis=-1)\n",
    "\n",
    "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "test_df['category'] = test_df['category'].replace(label_map)\n",
    "\n",
    "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a8d05",
   "metadata": {},
   "source": [
    "Visualize the prediction results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e6eb40c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'category'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/niteshkumar/SSD_Store_0_nvme/allPythoncodesWithPipEnv/BitsLearning/MLOps_Assignment/Assignment_2/bitsMtech_MLOps_Assignment_2/.mlopsAssignment2Env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'category'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m sample_test.iterrows():\n\u001b[32m      5\u001b[39m     filename = row[\u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     category = \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      7\u001b[39m     img = load_img(\u001b[33m\"\u001b[39m\u001b[33m./dogs-vs-cats/test1/\u001b[39m\u001b[33m\"\u001b[39m+filename, target_size=Image_Size)\n\u001b[32m      8\u001b[39m     plt.subplot(\u001b[32m6\u001b[39m, \u001b[32m3\u001b[39m, index+\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/niteshkumar/SSD_Store_0_nvme/allPythoncodesWithPipEnv/BitsLearning/MLOps_Assignment/Assignment_2/bitsMtech_MLOps_Assignment_2/.mlopsAssignment2Env/lib/python3.12/site-packages/pandas/core/series.py:1133\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1136\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/niteshkumar/SSD_Store_0_nvme/allPythoncodesWithPipEnv/BitsLearning/MLOps_Assignment/Assignment_2/bitsMtech_MLOps_Assignment_2/.mlopsAssignment2Env/lib/python3.12/site-packages/pandas/core/series.py:1249\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1248\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/niteshkumar/SSD_Store_0_nvme/allPythoncodesWithPipEnv/BitsLearning/MLOps_Assignment/Assignment_2/bitsMtech_MLOps_Assignment_2/.mlopsAssignment2Env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'category'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x2400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_test = test_df.head(18)\n",
    "sample_test.head()\n",
    "plt.figure(figsize=(12, 24))\n",
    "for index, row in sample_test.iterrows():\n",
    "    filename = row['filename']\n",
    "    category = row['category']\n",
    "    img = load_img(\"./dogs-vs-cats/test1/\"+filename, target_size=Image_Size)\n",
    "    plt.subplot(6, 3, index+1)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de67db3",
   "metadata": {},
   "source": [
    "Test your model performance on custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9230ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={\n",
    "    0:'cat',\n",
    "    1:'dog'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "267a1f63",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '__image_path_TO_custom_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m im=\u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m__image_path_TO_custom_image\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m im=im.resize(Image_Size)\n\u001b[32m     17\u001b[39m im=np.expand_dims(im,axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/niteshkumar/SSD_Store_0_nvme/allPythoncodesWithPipEnv/BitsLearning/MLOps_Assignment/Assignment_2/bitsMtech_MLOps_Assignment_2/.mlopsAssignment2Env/lib/python3.12/site-packages/PIL/Image.py:3512\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[32m   3511\u001b[39m     filename = os.fspath(fp)\n\u001b[32m-> \u001b[39m\u001b[32m3512\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3513\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3514\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '__image_path_TO_custom_image'"
     ]
    }
   ],
   "source": [
    "\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# im=Image.open(\"__image_path_TO_custom_image\")\n",
    "# im=im.resize(Image_Size)\n",
    "# im=np.expand_dims(im,axis=0)\n",
    "# im=np.array(im)\n",
    "# im=im/255\n",
    "# pred=model.predict_classes([im])[0]\n",
    "# print(pred,results[pred])\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "im=Image.open(\"__image_path_TO_custom_image\")\n",
    "im=im.resize(Image_Size)\n",
    "im=np.expand_dims(im,axis=0)\n",
    "im=np.array(im)\n",
    "im=im/255\n",
    "pred_probs = model.predict(im)\n",
    "pred = np.argmax(pred_probs, axis=-1)[0]\n",
    "print(pred, results[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9820f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd987c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed7943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlopsAssignment2Env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
